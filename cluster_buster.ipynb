{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes stat maps and generates a table where columns = clusters of contiguous voxels, rows = atlas labels, and cells = voxel count. Particularly useful for describing very large clusters that span multiple functional boundaries. Works best with pandas > version 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets\n",
    "from nilearn import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional software requirement:\n",
    "\n",
    "1. Access to fslmaths and cluster command from FSL install.\n",
    "2. Access to cerebellar atlas from FSL install. Location set to '/usr/share/fsl/5.0/data/atlases/Cerebellum/Cerebellum-MNIflirt-maxprob-thr25-2mm.nii.gz' for Linux by default.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load atlases to get voxel assignments from:\n",
    "\n",
    "- Dataset 1 = HO cortical atlas\n",
    "- Dataset 2 = HO subcortical atlas\n",
    "- Dataset 3 = Diedrichsen prob. cerebellar atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
    "dataset2 = datasets.fetch_atlas_harvard_oxford('sub-maxprob-thr25-2mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas1 = image.load_img(dataset1.maps)\n",
    "atlas2 = image.load_img(dataset2.maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas3 = image.load_img('/usr/share/fsl/5.0/data/atlases/Cerebellum/Cerebellum-MNIflirt-maxprob-thr25-2mm.nii.gz')\n",
    "atlas3labels = ['Background', 'Left I-IV', 'Right I-IV', 'Left V', 'Right V', 'Left VI', \n",
    "                'Vermis VI', 'Right VI', 'Left Crus I', 'Vermis Crus I', 'Right Crus I', \n",
    "                'Left Crus II', 'Vermis Crus II', 'Right Crus II', 'Left VIIb', \n",
    "                'Vermis VIIb', 'Right VIIb', 'Left VIIIa', 'Vermis VIIIa', 'Right VIIIa', \n",
    "                'Left VIIIb', 'Vermis VIIIb', 'Right VIIIb', 'Left IX', 'Vermis IX', \n",
    "                'Right IX', 'Left X', 'Vermis X', 'Right X']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare stat maps (input folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarize all stat maps. Threshold set arbitrarily to 0.9 here because all maps in input DIR are already thresholded at a much higher value to account for comparisons across multiple voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p intermediate\n",
    "for i in `ls input/*.nii.gz`; do\n",
    "    name=`echo $i | cut -d \".\" -f 1 | cut -d \"/\" -f 2`\n",
    "    echo \"Binarizing \" $name\n",
    "    fslmaths $i -thr 1 -bin intermediate/${name}_bin.nii.gz\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Break stat map up into clusters of contiguous voxels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "for i in `ls intermediate/*bin.nii.gz`; do\n",
    "    name=`echo $i | cut -d \".\" -f 1`\n",
    "    echo $name\n",
    "    cluster -i $i -t 0.9 --minextent=100 -o ${name}_cluster_index\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cluster gets its own image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p intermediate/individualclusters\n",
    "for f in intermediate/*cluster_index.nii.gz; do\n",
    "    b=`basename $f | cut -d \".\" -f 1`\n",
    "    echo $b\n",
    "    let i=1\n",
    "    max=`fslstats $f -R | awk '{printf(\"%d\", $2)}'`\n",
    "    echo $max\n",
    "    while [ $i -le $max ]; do\n",
    "        f2=intermediate/individualclusters/${b}_cluster${i}\n",
    "        fslmaths $f -thr $i -uthr $i -bin $f2 \n",
    "        let i=$i+1\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run table making step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablelist = []\n",
    "for i in sorted(glob.glob('intermediate/individualclusters/*')):\n",
    "    img = image.load_img(i)\n",
    "    # cortex:\n",
    "    result_img1 = image.math_img(\"img1 * img2\", img1=img, img2=atlas1)\n",
    "    flat1 = pd.Series(np.ndarray.flatten(result_img1.get_data())).value_counts()\n",
    "    # subcortex:\n",
    "    result_img2 = image.math_img(\"img1 * img2\", img1=img, img2=atlas2)\n",
    "    flat2 = pd.Series(np.ndarray.flatten(result_img2.get_data())).value_counts()\n",
    "    # cerebellum:\n",
    "    result_img3 = image.math_img(\"img1 * img2\", img1=img, img2=atlas3)\n",
    "    flat3 = pd.Series(np.ndarray.flatten(result_img3.get_data())).value_counts()\n",
    "    for j in range(len(flat1)):\n",
    "        print(i.split('/')[2], dataset1.labels[int(flat1.index[j])], flat1[flat1.index[j]])\n",
    "        tablelist.append([i.split('/')[2], dataset1.labels[int(flat1.index[j])], flat1[flat1.index[j]]])\n",
    "    for j in range(len(flat2)):\n",
    "        print(i.split('/')[2], dataset2.labels[int(flat2.index[j])], flat2[flat2.index[j]])\n",
    "        tablelist.append([i.split('/')[2], dataset2.labels[int(flat2.index[j])], flat2[flat2.index[j]]])\n",
    "    for j in range(len(flat3)):\n",
    "        print(i.split('/')[2], atlas3labels[j], flat3[flat3.index[j]])\n",
    "        tablelist.append([i.split('/')[2], atlas3labels[j], flat3[flat3.index[j]]])\n",
    "#         tablelist.append([i.split('/')[1], dataset2.labels[int(flat.index[j])], flat[flat.index[j]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableframe = pd.DataFrame(tablelist, columns=['map', 'region', 'voxels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary \"areas\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toremove = ['Background', 'Right Cerebral Cortex', 'Left Cerebral Cortex', 'Right Cerebral Cortex ', 'Left Cerebral Cortex ', 'Right Cerebral White Matter', 'Left Cerebral White Matter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableframe = tableframe[~tableframe['region'].isin(toremove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold based on number of voxels in each cluster subcomponent (already thresholded clusters earlier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tableframe = tableframe[tableframe['voxels'] > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot to make each cluster its own column. Required Pandas 1.3 to make sure the cortex, subcortex, and cerebellar rows stay separated without manually specifying row order. If pandas < 1.3, comment out sort=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.pivot_table(tableframe, index=['region'],\n",
    "                    fill_value=0, values='voxels', columns=['map'], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save table with threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires openpyxl to save to excel directly:\n",
    "# table.to_excel('clusters.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv('clusters.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
